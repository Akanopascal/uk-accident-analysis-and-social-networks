{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f58b3db-70ba-45b1-b8d7-9d07fe8a1e60",
   "metadata": {},
   "source": [
    "## Imports Statments\n",
    "Importing the Necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293a12ba-2f9b-4255-95f5-4362cb5c7f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "import warnings\n",
    "import folium\n",
    "import ydata_profiling\n",
    "\n",
    "from time import time\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from folium import CircleMarker\n",
    "from folium.plugins import HeatMap\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.cluster import DBSCAN\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from sklearn.feature_selection import (SelectKBest, chi2, f_regression, f_classif)\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from ydata_profiling import ProfileReport\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier, LocalOutlierFactor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcbba2c-5ed9-4f3a-ab32-8d62ef790978",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "Loading the Data from the Database and defining helper Classes and function to aid data retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed00323-014d-402c-8891-9a9d1d9fb9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatabaseUtil(object):\n",
    "    \"\"\"\n",
    "    Class for extracting details from the Database & tabulating Queries\n",
    "    \"\"\"\n",
    "    def __init__(self, db_name):\n",
    "        \"\"\"\n",
    "        Constructor that initializes the class with The Database Name\n",
    "        Connection and Cursor\n",
    "        \"\"\" \n",
    "        self.db_name = db_name\n",
    "        self.connection = None\n",
    "        self.cursor = None\n",
    "        \n",
    "        \n",
    "    def connect_database(self):\n",
    "        \"\"\"\n",
    "        Connects to the database, Fetch all Table names\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.connection = sqlite3.connect(self.db_name)\n",
    "            self.cursor = self.connection.cursor()\n",
    "            print(\"Successfully Connected to the database\")\n",
    "        except sqlite3.Error as e:\n",
    "            print(\"Error connecting to the database:\", e)\n",
    "            \n",
    "        self.cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "        self.tables = self.cursor.fetchall()\n",
    "    \n",
    "    def disconnect_database(self):\n",
    "        \"\"\"\n",
    "        Disconnects from the database\n",
    "        \"\"\"\n",
    "        if self.connection:\n",
    "            self.cursor.close()\n",
    "            self.connection.close()\n",
    "            print(\"Disconnected from the database\")\n",
    "\n",
    "    def get_table_names_and_attributes(self):\n",
    "        \"\"\"\n",
    "        Get Table Names and Attributes\n",
    "        \"\"\"\n",
    "        if not self.connection or not self.cursor:\n",
    "            print(\"Please connect a database first\")\n",
    "            return\n",
    "        \n",
    "        accident_data_attribute = {} \n",
    "        for table in self.tables:   \n",
    "            table_name = table[0]\n",
    "\n",
    "            table_attributes = self.cursor.execute(f\"PRAGMA table_info({table_name})\").fetchall()\n",
    "            accident_data_attribute[table_name] = [column[1] for column in table_attributes]\n",
    "        return accident_data_attribute\n",
    "    \n",
    "    def get_row_counts(self):\n",
    "        \"\"\"\n",
    "        Get Table Row Counts\n",
    "        \"\"\"\n",
    "        if not self.connection or not self.cursor:\n",
    "            print(\"Please connect a database first\")\n",
    "            return\n",
    "        \n",
    "        for table in self.tables:\n",
    "            table_name = table[0]\n",
    "            self.cursor.execute(f\"SELECT COUNT(*) FROM {table_name};\")\n",
    "            row_count = self.cursor.fetchone()[0]\n",
    "            print(f\"Table Name: {table_name}, Row Counts: {row_count}\")\n",
    "            \n",
    "    def get_primary_keys(self):\n",
    "        \"\"\"\n",
    "        Get the list of primary keys for each table in the database.\n",
    "        \"\"\"\n",
    "        if not self.connection or not self.cursor:\n",
    "            print(\"Please connect a database first\")\n",
    "            return\n",
    "\n",
    "        primary_keys = {}\n",
    "\n",
    "        for table in self.tables:\n",
    "            table_name = table[0]\n",
    "            table_info = self.cursor.execute(f\"PRAGMA table_info({table_name})\").fetchall()\n",
    "        \n",
    "            # Find all columns where pk flag == 1\n",
    "            pk_columns = [col[1] for col in table_info if col[-1] == 1]\n",
    "\n",
    "            if pk_columns:\n",
    "                primary_keys[table_name] = pk_columns if len(pk_columns) > 1 else pk_columns[0]\n",
    "            else:\n",
    "                primary_keys[table_name] = None  # No PK found\n",
    "\n",
    "        return primary_keys\n",
    "\n",
    "\n",
    "    def tabulate_query(self, query):\n",
    "        \"\"\"\n",
    "        Using Query to make a dataframe\n",
    "        \"\"\"\n",
    "        if not self.connection or not self.cursor:\n",
    "            print(\"Please connect a database first\")\n",
    "            return\n",
    "        \n",
    "        cmd = query\n",
    "        data_frame = pd.read_sql_query(query, self.connection)\n",
    "        return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f4fcf6-6d12-4788-8a10-c3024ebf54cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_data_v1 = DatabaseUtil('accident_data_v1.0.0_2023.db') # Initializing Database\n",
    "accident_data_v1.connect_database() # Connecting the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1aa314-fd02-4a1e-ba41-e05bc877b8e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "table_names_and_attributes = accident_data_v1.get_table_names_and_attributes() # Get table names and attributes\n",
    "table_names_and_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04551646-86f5-42a5-967f-aa0e04ceff55",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_primary_keys = accident_data_v1.get_primary_keys() # Get Primarys Keys\n",
    "table_primary_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a05e0b-656e-4c60-b519-60609dfc5e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_counts = accident_data_v1.get_row_counts() # Get Row Count\n",
    "row_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97816ca-049a-4a6d-b1e7-80608b296f0e",
   "metadata": {},
   "source": [
    "### Extract Data FROM 2019 Into Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c92bbf1-9357-4341-8470-bc223d8dd885",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccidentAnalysis:\n",
    "    \"\"\"\n",
    "    Class to manage accident data analysis for 2019.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, db_util):\n",
    "        \"\"\"\n",
    "        Initializes with a DatabaseUtil object (already connected).\n",
    "        \"\"\"\n",
    "        self.db_util = db_util\n",
    "        self.accidents = None\n",
    "        self.vehicles = None\n",
    "        self.casualties = None\n",
    "\n",
    "    def load_data(self, year=2019):\n",
    "        \"\"\"\n",
    "        Loads accidents, vehicles, and casualties data for the given year.\n",
    "        \"\"\"\n",
    "        print(f\"Loading data for year {year}...\")\n",
    "\n",
    "        query_template = \"SELECT * FROM {table} WHERE accident_year = {year}\"\n",
    "\n",
    "        self.accidents = self.db_util.tabulate_query(query_template.format(table=\"accident\", year=year))\n",
    "        self.vehicles = self.db_util.tabulate_query(query_template.format(table=\"vehicle\", year=year))\n",
    "        self.casualties = self.db_util.tabulate_query(query_template.format(table=\"casualty\", year=year))\n",
    "\n",
    "        print(f\"Data loaded: {len(self.accidents)} accidents, {len(self.vehicles)} vehicles, {len(self.casualties)} casualties\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d042e8e3-b82f-44bc-81a2-fe01db192b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to DB using existing class\n",
    "db_util = DatabaseUtil(\"accident_data_v1.0.0_2023.db\")\n",
    "db_util.connect_database()\n",
    "\n",
    "# Create AccidentAnalysis object\n",
    "analysis = AccidentAnalysis(db_util)\n",
    "\n",
    "#  Load 2019 data\n",
    "analysis.load_data(2019)\n",
    "\n",
    "# View results\n",
    "analysis.accidents.head()\n",
    "analysis.vehicles.head()\n",
    "analysis.casualties.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176b1796-ec7f-40f5-a170-0b18a1bca273",
   "metadata": {},
   "source": [
    "**Disconnecting the Database after extracting all needed data into dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a128b9-4817-44cb-adcf-0c5009c67eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_data_v1.disconnect_database() # Disconecting the Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3d82a9-0169-46eb-bf77-2857ef621e56",
   "metadata": {},
   "source": [
    "## Data Cleaning, EDA and Imputation\n",
    "Cleaning data, filling missing values and Visualise the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1371a21-7758-455f-8d96-4dfac47561c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanUpAnalyzeData(object):\n",
    "    \"\"\"\n",
    "    Class cleaning data and filling missing values.\n",
    "    \"\"\"\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Constructor that initializes the class with the Dataframe\n",
    "        \"\"\" \n",
    "        self.data = data\n",
    "        self.columns_with_unknown_values = {}\n",
    "        return data.info()\n",
    "    \n",
    "    def get_columns_with_initial_nan_values(self):\n",
    "        \"\"\"\n",
    "        Get names of columns containing missing values\n",
    "        \"\"\"\n",
    "        columns_with_missing_values = self.data.columns[self.data.isnull().any()]\n",
    "        if len(columns_with_missing_values) == 0:\n",
    "            return 'No Initial NAN values'\n",
    "        else:\n",
    "            for column in columns_with_missing_values:\n",
    "                num_missing_values = self.data[column].isnull().sum()\n",
    "                print(f\"column '{column}' has {num_missing_values} missing values.\")\n",
    "                \n",
    "            \n",
    "            percentage_nan = (self.data.isna().sum().sum() /  len(self.data)) * 100\n",
    "            if percentage_nan < 1:\n",
    "                self.data.dropna(inplace=True)\n",
    "                return(f\"\"\"The percentage of inital NaN values in the DataFrame is: {percentage_nan:.5f}% less than 1% and automatically dropped\"\"\")\n",
    "            else:\n",
    "                return(f\"The percentage of inital NaN values in the DataFrame is: {percentage_nan:.5f}%\")\n",
    "            \n",
    "    def display_columns_with_unknown_values(self):\n",
    "        \"\"\"\n",
    "        Display Columns with -1 or empty spaces.\n",
    "        \"\"\"\n",
    "        missing = self.data.isin([-1, '-1', '']).sum().to_dict()\n",
    "        columns_with_unknown_values = {key: value for key, value in missing.items() if value > 0}\n",
    "        \n",
    "        if len(columns_with_unknown_values) > 0:\n",
    "            self.columns_with_unknown_values = columns_with_unknown_values\n",
    "            return columns_with_unknown_values\n",
    "        else:\n",
    "            return \"No columns containing - 1 or '' \"\n",
    "    \n",
    "    def missing_data_imputation(self):\n",
    "        \"\"\"\n",
    "        Filling Missing the Values\n",
    "        \"\"\"\n",
    "        if len(self.columns_with_unknown_values) >= 1:\n",
    "            for column, missing_val_count in self.columns_with_unknown_values.items():\n",
    "                # if a column missing value is greater than 40% drop column else fill with the mode value.\n",
    "                if ((missing_val_count /  len(self.data)) * 100 ) > 40:\n",
    "                    self.data = self.data.drop(column, axis=1)\n",
    "                    print(f\"Dropped {column} Column for having over 40% Missing Values\")\n",
    "                    \n",
    "                else:\n",
    "                    self.data[column].replace(['-1', -1, ''], np.nan, inplace=True) \n",
    "                    # filling age values with the Median\n",
    "                    if 'age_' in column:\n",
    "                        median_value = int(round(self.data[column].median()))\n",
    "                        self.data[column].fillna(median_value, inplace=True)\n",
    "                        self.data[column] = self.data[column].astype(int)\n",
    "                        print(f\"Filled the {column} column\")\n",
    "                    else:\n",
    "                        # filling other categorical and string values with the mode.\n",
    "                        mode_value = self.data[column].mode()[0]\n",
    "                        if self.data[column].dtype == float or  self.data[column].dtype == int:\n",
    "                            self.data[column].fillna(int(mode_value), inplace=True)\n",
    "                            self.data[column] = self.data[column].astype(int)\n",
    "                            print(f\"Filled the {column} column\")\n",
    "                        else:\n",
    "                            self.data[column].fillna(mode_value , inplace=True)\n",
    "                            print(f\"Filled the {column} column\")\n",
    "        else:\n",
    "            print('No Missing Column Values to Fill')\n",
    "\n",
    "    def overview_visualization(self, title=str):\n",
    "        \"\"\"\n",
    "        Using Pandas Profilling to visualize the dataframe.\n",
    "        \"\"\"\n",
    "        report = ProfileReport(self.data, title=title, progress_bar=True)\n",
    "        return report\n",
    "        \n",
    "    def finalizie_cleaning(self):\n",
    "        print('Finished Data Cleaning')\n",
    "        return self.data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c03063a-e6ef-450d-9431-ce695b434f8f",
   "metadata": {},
   "source": [
    "### Accident Data Cleaning\n",
    "**cad means 'Clean Up Analyze Data'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a3131a-73da-4206-a3a8-4f0c1ac9e89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cad_accident_data = CleanUpAnalyzeData(analysis.accidents) # Initializing CLeaning and Overview Analysis to the accident data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55483ab-289a-46ac-8d3e-3184b30e188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cad_accident_data.get_columns_with_initial_nan_values() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed7083b-f9a3-4aa0-907c-a4f7adc41cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cad_accident_data.display_columns_with_unknown_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4778b94-68c5-4c8d-a3cb-8d13ed5eb507",
   "metadata": {},
   "outputs": [],
   "source": [
    "cad_accident_data.missing_data_imputation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b173483a-1ec0-4b18-8beb-c50015e795e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cad_accident_data.overview_visualization(\"Accident Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a11151-a5d3-4db4-9923-a120fad8a25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_data = cad_accident_data.finalizie_cleaning()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecefa489-5edd-4a38-89ce-3ec26e0fddc1",
   "metadata": {},
   "source": [
    "### Vehicle Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0687212f-16b4-4569-87e6-29ec54b102f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cad_vehicle_data = CleanUpAnalyzeData(analysis.vehicles) #Initializing CLeaning and Overview Analysis to the vehicle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce95f6a-9c49-44b7-bded-b054fee115c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cad_vehicle_data.get_columns_with_initial_nan_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e304fe8-6a0f-4290-af42-38631c906d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cad_vehicle_data.display_columns_with_unknown_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382de161-f84a-403d-98a0-cc855431af8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cad_vehicle_data.missing_data_imputation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf2beff-79ec-4ee5-ace4-cac878d971d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cad_vehicle_data.overview_visualization(\"Vehicle Table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6533db12-6fc3-42f6-9560-8fe157995d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_data = cad_vehicle_data.finalizie_cleaning()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3b3a9c-9551-445f-9584-aecc22ab59b4",
   "metadata": {},
   "source": [
    "### Casualty Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3100eb63-7f33-4e6d-9056-b0763798c516",
   "metadata": {},
   "outputs": [],
   "source": [
    "cad_casualty_data = CleanUpAnalyzeData(analysis.casualties) #Initializing CLeaning and Overview Analysis to the casualty data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08f4d64-5466-4d6b-9864-bbbaca5f505a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cad_casualty_data.get_columns_with_initial_nan_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90336619-30c7-4219-a89e-5a94bcc859d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cad_casualty_data.display_columns_with_unknown_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e966d301-e6d7-490e-bfb3-1fec27c81615",
   "metadata": {},
   "outputs": [],
   "source": [
    "cad_casualty_data.missing_data_imputation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9c8d9b-a4ac-485a-b50b-e44946db0db2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cad_casualty_data.overview_visualization(\"Casualty Table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb225e2-fefd-4e34-b0df-a1d49c918694",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "casualty_data = cad_casualty_data.finalizie_cleaning()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d3931a-cd6d-4c52-9d6a-956ee9b3b8c0",
   "metadata": {},
   "source": [
    "## Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8525f073-f65f-45d4-af26-1f6a47aa5f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0582f790-d8e5-4b48-903b-397d6e0fb6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "guide_path = 'dft-road-casualty-statistics-road-safety-open-dataset-data-guide-2024.xlsx'\n",
    "\n",
    "try:\n",
    "    data_guide = pd.read_excel(guide_path)\n",
    "    data_guide.columns = data_guide.columns.str.strip().str.lower()  # Standardize columns\n",
    "    print(\" 2024 data guide loaded.\")\n",
    "except Exception as e:\n",
    "    print(f\" Error loading data guide: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1387e3c-edb8-40a4-889b-db867fdbbcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(field_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Return a dictionary mapping code → label for a given field name.\n",
    "    Works with the 2024 road safety guide and normalizes field names.\n",
    "    \"\"\"\n",
    "    if 'field name' not in data_guide.columns or 'code/format' not in data_guide.columns or 'label' not in data_guide.columns:\n",
    "        raise ValueError(\"Expected columns not found in data_guide.\")\n",
    "\n",
    "    match = data_guide[data_guide['field name'].str.strip().str.lower() == field_name.strip().lower()]\n",
    "    \n",
    "    if match.empty:\n",
    "        print(f\"No matching field found for '{field_name}'.\")\n",
    "        return {}\n",
    "    \n",
    "    # Build dictionary with safe keys (convert to int if possible)\n",
    "    result = {}\n",
    "    for _, row in match.iterrows():\n",
    "        key = row['code/format']\n",
    "        try:\n",
    "            key = int(float(key))\n",
    "        except:\n",
    "            key = str(key).strip()\n",
    "        result[key] = str(row['label']).strip()\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a61cc36-83c0-4ca4-908c-baa822f7f91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "created_plots = {}\n",
    "\n",
    "def display_plot(ax, title, x, y,\n",
    "                 show_x_bar=False, show_y_bar=False,\n",
    "                 small=False, long=False, wide=False,\n",
    "                 rotate_x=False, save_as=None):\n",
    "\n",
    "    title_fontsize = 12\n",
    "    label_fontsize = 10\n",
    "    params_fontsize = 12\n",
    "    legend_fontsize = 15\n",
    "    sns.set_style('whitegrid')\n",
    "    \n",
    "    # plot sizing\n",
    "    if long:\n",
    "        size = (8, 10)\n",
    "    elif wide:\n",
    "        size = (18, 15)\n",
    "        label_fontsize = 9\n",
    "    elif small:\n",
    "        size = (6, 6)\n",
    "        title_fontsize = 8\n",
    "        label_fontsize = 8\n",
    "    else:\n",
    "        size = (12, 12)\n",
    "\n",
    "    fig = ax.get_figure()\n",
    "    fig.set_size_inches(*size)\n",
    "\n",
    "    # rotate x-axis\n",
    "    if rotate_x:\n",
    "        for label in ax.get_xticklabels():\n",
    "            label.set_rotation(90)\n",
    "\n",
    "    # annotate bars\n",
    "    for p in ax.patches:\n",
    "        if show_x_bar and not np.isnan(p.get_height()):\n",
    "            ax.annotate(f'{round(p.get_height())}',\n",
    "                        (p.get_x() + p.get_width() / 2, p.get_height()),\n",
    "                        ha='center', va='bottom', fontsize=params_fontsize)\n",
    "        if show_y_bar and not np.isnan(p.get_width()):\n",
    "            ax.annotate(f'{round(p.get_width())}',\n",
    "                        (p.get_width() + 5, p.get_y() + p.get_height() / 2),\n",
    "                        va='center', fontsize=params_fontsize)\n",
    "\n",
    "    ax.set_title(title, fontsize=title_fontsize)\n",
    "    ax.set_xlabel(x, fontsize=label_fontsize)\n",
    "    ax.set_ylabel(y, fontsize=label_fontsize)\n",
    "    ax.tick_params(labelsize=params_fontsize)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    created_plots[title] = fig\n",
    "\n",
    "    if save_as:\n",
    "        fig.savefig(save_as, dpi=300, bbox_inches='tight')\n",
    "\n",
    "    return plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aea4798-4d82-4848-87c2-16f0aea909ae",
   "metadata": {},
   "source": [
    "## Accident Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1761ffe9-febe-49f6-8e2e-c221c5cea134",
   "metadata": {},
   "source": [
    "Are there any particular hours of the day, and days of the week, on which these accidents are likely to occur?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e4ff9e-d07b-4d9d-9244-be27e169f30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Get the label mapping for 'day_of_week'\n",
    "day_names = get_label('day_of_week')\n",
    "day_order = list(day_names.values())\n",
    "\n",
    "# Map the readable day names to the dataset\n",
    "accident_data['day_name'] = accident_data['day_of_week'].map(day_names)\n",
    "\n",
    "#  Plot the countplot\n",
    "day_of_the_week_dist = sns.countplot(\n",
    "    data=accident_data,\n",
    "    x='day_name',\n",
    "    order=day_order,\n",
    "    palette='rocket_r',\n",
    "    edgecolor='black',\n",
    "    alpha=0.8\n",
    ")\n",
    "\n",
    "#  Annotate and display the plot\n",
    "display_plot(day_of_the_week_dist, \n",
    "             'FIGURE 2: ACCIDENT DAY OF THE WEEK DISTRIBUTION', \n",
    "             'DAY', 'COUNT', \n",
    "             show_x_bar=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97434dad-2097-43f0-99e9-3b324af3ed0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# describe day of the week\n",
    "accident_data['day_of_week'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7267cc8-2083-4de6-b34e-34cadb6a2fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accident time distribution\n",
    "accident_data['decimal_time'] =  [int(date.split(':')[0]) + (int(date.split(':')[1]) / 60)  \n",
    "                                                  for date in accident_data['time'] ]\n",
    "day_of_the_time_dist = sns.histplot(accident_data, x='decimal_time', bins=20,\n",
    "                                  edgecolor='black', alpha=0.4)\n",
    "\n",
    "# initalize the display plot function\n",
    "display_plot(day_of_the_time_dist, 'FIGURE 3: ACCIDENT TIME OF DAY DISTRIBUTION', 'TIME', 'COUNT', wide=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4df1c9-0575-44c2-b1d2-2b3ead0dd512",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get month from date\n",
    "accident_data['month'] = pd.to_datetime(accident_data['date'], format='%d/%m/%Y').dt.month \n",
    "\n",
    "# plot accident severity by month\n",
    "accident_data['accident_severity_label'] = accident_data['accident_severity'].map(\n",
    "    get_label('accident_severity'))\n",
    "accident_serverity_by_month = sns.countplot(x='month', hue='accident_severity_label', \n",
    "                                            data=accident_data, palette='Paired', \n",
    "                                            orient='v', dodge=False, edgecolor='black', alpha=0.8)\n",
    "plt.legend(title='severity')\n",
    "\n",
    "# initalize the display plot function\n",
    "display_plot(accident_serverity_by_month, 'FIGURE 1: ACCIDENT SEVERITY BY MONTH', 'MONTH', \n",
    "             'COUNT', show_x_bar=True, wide = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800ca936-815d-4e84-b871-d8609f8c0e2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot accident severity by day of the week\n",
    "severity_day_of_the_week_dist = sns.countplot(data=accident_data, x='day_name',  \n",
    "                                            hue='accident_severity_label',\n",
    "                                            order=day_order, palette='Paired',\n",
    "                                            edgecolor='black', dodge=False, alpha=0.8)\n",
    "plt.legend(title='severity')\n",
    "\n",
    "# initalize the display plot function\n",
    "display_plot(severity_day_of_the_week_dist, 'ACCIDENT SEVERITY DAY OF THE WEEK', 'DAY', \n",
    "             'COUNT', show_x_bar=True, wide=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86322ab1-01e7-4c12-b259-8274ab032ccf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot accident severity based on time on day\n",
    "severity_hour_dist = sns.histplot(data=accident_data, x='decimal_time', \n",
    "                                   hue='accident_severity_label', bins=20,\n",
    "                                     palette='Paired', \n",
    "                                     legend= True, \n",
    "                                     edgecolor='black', multiple=\"stack\")\n",
    "\n",
    "# initalize the display plot function\n",
    "display_plot(severity_hour_dist, 'ACCIDENT SEVERITY BY TIME OF DAY', 'TIME', 'COUNT', wide = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5c98f0-bd3f-4f9b-97f4-03bc2ac89e17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot accident severity based on road type\n",
    "accident_data['road_type_label'] = accident_data['road_type'].map(\n",
    "    get_label('road_type'))\n",
    "\n",
    "accident_serverity_road_type = sns.countplot(x='road_type_label', hue='accident_severity_label', \n",
    "                                            data=accident_data, palette='Paired',\n",
    "                                            orient='h', dodge=False, edgecolor='black', alpha=0.8)\n",
    "plt.legend(title='severity')\n",
    "\n",
    "# initalize the display plot function\n",
    "display_plot(accident_serverity_road_type, 'FIGURE 5: ACCIDENT SEVERITY BY ROAD TYPE','COUNT', \n",
    "             'ROAD TYPE', wide=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6ed443-2565-40fe-9acc-97fae4d91124",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# accident severity by roady type by weather\n",
    "accident_data['light_conditions_label'] = accident_data['light_conditions'].map(\n",
    "    get_label('light_conditions'))\n",
    "\n",
    "accident_serverity_road_type = sns.countplot(y='light_conditions_label', hue='accident_severity_label', \n",
    "                                            data=accident_data, palette='Paired',\n",
    "                                            orient='h', dodge=False, edgecolor='black', alpha=0.8)\n",
    "plt.legend(title='severity')\n",
    "\n",
    "# initalize the display plot function\n",
    "display_plot(accident_serverity_road_type,'FIGURE 4: ACCIDENT SEVERITY BY LIGHT CONDITIONS', \n",
    "             'COUNT', 'LIGHT CONDITIONS', wide=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f567da-0688-4ef0-a52d-7a7c7acf3651",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# accident severity by weather\n",
    "accident_data['weather_conditions_label'] = accident_data['weather_conditions'].map(\n",
    "    get_label('weather_conditions'))\n",
    "\n",
    "accident_serverity_road_type = sns.countplot(y='weather_conditions_label', hue='accident_severity_label', \n",
    "                                            data=accident_data, palette='Paired',\n",
    "                                            orient='h', dodge=False, edgecolor='black', alpha=0.8)\n",
    "plt.legend(title='severity')\n",
    "\n",
    "# initalize the display plot function\n",
    "display_plot(accident_serverity_road_type, 'ACCIDENT SEVERITY BY WEATHER CONDITIONS','COUNT', \n",
    "             'WEATHER', wide =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de433349-7457-4c24-a2bd-72064a384fc7",
   "metadata": {},
   "source": [
    "### Accident & Casualty Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261e0f9c-b752-4bae-9c05-9bd8c8288ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge accident casualty\n",
    "accident_casualty =  pd.merge(accident_data, casualty_data, on='accident_index')\n",
    "print(f\"Number of duplicates: {accident_casualty.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e467d0-f62e-483b-afa6-7a0cb09f77a0",
   "metadata": {},
   "source": [
    "*For pedestrians involved in accidents, are there significant hours of the day, and days of the week, on which they are more likely to be involved?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0de75e-7ffc-4c56-837f-58d3a759e953",
   "metadata": {},
   "outputs": [],
   "source": [
    "pedestrian_accident_hours_day = accident_casualty[accident_casualty[\"casualty_class\"] == 3].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c5c2b0-b0d6-47a7-8dcb-a1687388f39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot pedestrian accidents by day of week\n",
    "accident_casualty['day_name'] = accident_casualty['day_of_week'].map(day_names)\n",
    "\n",
    "pedestrian_accident_day_dist = sns.countplot(data=pedestrian_accident_hours_day,\n",
    "                     x='day_name',\n",
    "                     order=day_order, palette='rocket_r',\n",
    "                     edgecolor='black', alpha=0.8)\n",
    "\n",
    "\n",
    "display_plot(pedestrian_accident_day_dist, 'FIGURE 11: PEDESTRIAN ACCIDENT DAY OF THE WEEK DISTRIBUTION', 'DAY', \n",
    "                                            'COUNT', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dded39-3c94-482e-88a1-1bfcd90daee7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# plot pedestrian accident hours\n",
    "pedestrian_accident_hours_dist = sns.histplot(pedestrian_accident_hours_day, \n",
    "                                             x='decimal_time', bins=20, \n",
    "                                              kde=True,\n",
    "                                             edgecolor='black', alpha=0.4)\n",
    "\n",
    "# initalize the display plot function\n",
    "display_plot(pedestrian_accident_hours_dist, 'FIGURE 12: PEDESTRIAN ACCIDENT TIME OF DAY DISTRIBUTION', \n",
    "             'TIME', 'COUNT', wide=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8c18b1-31b2-4cb5-b108-4e89c645d6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe pedestrain time\n",
    "pedestrian_accident_hours_day['decimal_time'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335b08c7-2941-4592-8f0f-87a87258f99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map sex of casualty label\n",
    "accident_casualty['sex_label'] = accident_casualty['sex_of_casualty'].map(get_label('sex_of_casualty'))\n",
    "\n",
    "# plot severity by sex\n",
    "severity_by_sex =  sns.countplot(x='accident_severity_label', hue='sex_label', \n",
    "                                 data=accident_casualty, palette='Paired',\n",
    "                                edgecolor='black', alpha=0.8)\n",
    "plt.legend(title='Gender')\n",
    "\n",
    "# initalize the display plot function\n",
    "display_plot(severity_by_sex, 'ACCIDENT SEVERITY DISTRIBUTION BY GENDER', 'SEVERITY', 'COUNT', True, wide=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d4e9a2-644d-46fb-ac91-48cf5d4d30c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map casualty class label\n",
    "accident_casualty['class_label'] = accident_casualty['casualty_class'].map(get_label('casualty_class'))\n",
    "\n",
    "casualty_by_sex =  sns.countplot(x='class_label', hue='sex_label', \n",
    "                                 data=accident_casualty, palette='Paired',\n",
    "                                edgecolor='black', alpha=0.9, dodge=True)\n",
    "plt.legend(title='Gender')\n",
    "\n",
    "# initalize the display plot function\n",
    "display_plot(casualty_by_sex, 'FIGURE 9: CASUALTY CLASS BY GENDER', 'CLASS', 'COUNT', True, wide=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0a4e41-7596-4e54-bd12-fc95689a1b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot casualty by sex\n",
    "casualty_by_sex =  sns.countplot(x='class_label', hue='accident_severity_label', \n",
    "                                 data=accident_casualty, palette='Paired',\n",
    "                                edgecolor='black', alpha=0.8, dodge=True)\n",
    "plt.legend(title='severity')\n",
    "\n",
    "# initalize the display plot function\n",
    "display_plot(casualty_by_sex, 'FIGURE 10: CASUALTY CLASS BY ACCIDENT SEVERITY', 'CLASS', 'COUNT', True, wide=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10339a08-ada5-4922-8df0-3b24760a4371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add casualty severity \n",
    "# plot casualty by sex\n",
    "accident_casualty['casualty_severity_label'] = accident_casualty['casualty_severity'].map(\n",
    "    get_label('casualty_severity'))\n",
    "casualty_by_sex =  sns.countplot(x='casualty_severity_label', hue='sex_label', \n",
    "                                 data=accident_casualty, palette='Paired',\n",
    "                                edgecolor='black', alpha=0.8, dodge=True)\n",
    "plt.legend(title='Gender')\n",
    "\n",
    "# initalize the display plot function\n",
    "display_plot(casualty_by_sex, 'CASUALTY SEVERITY BY GENDER', 'CLASS', 'COUNT', True, wide= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e26021b-1d6b-4b89-a581-c5c249edd03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting casulty class by severity\n",
    "casualty_by_sex =  sns.countplot(x='class_label', hue='casualty_severity_label', \n",
    "                                 data=accident_casualty, palette='Paired',\n",
    "                                edgecolor='black', alpha=0.8, dodge=True)\n",
    "plt.legend(title='severity')\n",
    "\n",
    "# initalize the display plot function\n",
    "display_plot(casualty_by_sex, 'CASUALTY CLASS BY CASUALTY SEVERITY', 'CLASS', 'COUNT', True, wide = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4be01bd-b4c6-42ac-9ffd-8925362d0d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map casualty type label\n",
    "accident_casualty['casualty_type_label'] = accident_casualty['casualty_type'].map(get_label('casualty_type'))\n",
    "\n",
    "top_10_casualty_classes = accident_casualty['casualty_type_label'].value_counts().nlargest(10).index\n",
    "\n",
    "# Filter the DataFrame to keep only the rows with the top 10 casualty classes\n",
    "accident_casualty_top_10 = accident_casualty[accident_casualty['casualty_type_label'].isin(top_10_casualty_classes)]\n",
    "\n",
    "# Create a stacked countplot using Seaborn with the filtered data\n",
    "casualty_type_by_sex_top_10 = sns.countplot(y='casualty_type_label', hue='sex_label', \n",
    "                                            data=accident_casualty_top_10, palette='Paired', \n",
    "                                            orient='h', dodge=False, edgecolor='black', alpha=0.7)\n",
    "\n",
    "plt.legend(title='Gender')\n",
    "\n",
    "# initalize the display plot function\n",
    "display_plot(casualty_type_by_sex_top_10, 'TOP 10 CASUALTY TYPE BY GENDER', 'COUNT', 'TYPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafa2776-a205-4f87-a293-5a048424a029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mad age band label\n",
    "accident_casualty['age_band_label'] = accident_casualty['age_band_of_casualty'].map(\n",
    "    get_label('age_band_of_casualty'))\n",
    "\n",
    "# define correct age order\n",
    "agebandidx = ['0 - 5', '6 - 10',\n",
    "              '11 - 15', '16 - 20', \n",
    "              '21 - 25', '26 - 35', \n",
    "              '36 - 45', '46 - 55',\n",
    "              '56 - 65', '66 - 75', \n",
    "              'Over 75']\n",
    "\n",
    "# plot casualty by sex age group\n",
    "casualty_by_sex_age_group =  sns.countplot(x='age_band_label', hue='sex_label', \n",
    "                                 data=accident_casualty, palette='Paired', orient='h',\n",
    "                                edgecolor='black', alpha=0.8, \n",
    "                                order=agebandidx, dodge=False)\n",
    "plt.legend(title='Gender')\n",
    "\n",
    "# initalize the display plot function\n",
    "display_plot(casualty_by_sex_age_group, 'FIGURE 8: CASUALTY AGE BAND BY GENDER', 'AGE BAND', 'COUNT', wide =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db107cec-b5f6-4188-8058-1340a40c3c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pedestrian movement by severity\n",
    "pedestrian_accident_hours_day['pedestrian_movement_label'] = pedestrian_accident_hours_day['pedestrian_movement'].map(\n",
    "    get_label('pedestrian_movement'))\n",
    "\n",
    "casualty_by_pedestrian_movement =  sns.countplot(y='pedestrian_movement_label', hue='accident_severity_label', \n",
    "                                 data=pedestrian_accident_hours_day, palette='Paired',\n",
    "                                edgecolor='black', alpha=0.8, dodge=True)\n",
    "plt.legend(title='Accident Severity')\n",
    "\n",
    "# initalize the display plot function\n",
    "display_plot(casualty_by_pedestrian_movement, 'SEVERITY BY PEDESTRIAN MOVEMENT', 'CLASS', 'COUNT')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed8907f-9f2d-48de-9aa4-ffc4dac0e83c",
   "metadata": {},
   "source": [
    "### Accidents & Vehicles Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b9091b-dcf5-492f-9f83-5054f387c3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_vehicle = pd.merge(accident_data, vehicle_data, on='accident_index')\n",
    "print(f\"Number of duplicates: {accident_vehicle.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafb281c-a8e0-4b3f-9440-f8ec6a3998d7",
   "metadata": {},
   "source": [
    "*For motorbikes, are there significant hours of the day, and days of the week, on which accidents occur? We suggest a focus on: Motorcycle 125cc and under, Motorcycle over 125cc and up to 500cc, and Motorcycle over 500cc.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ae2a0c-1c59-4ff9-a959-458f0a020cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group motorcycle accident\n",
    "motorcycle_accident = accident_vehicle[accident_vehicle[\"vehicle_type\"].isin([5, 4, 3])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad32f49-f4b7-46e5-8a1f-916da75efe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map motorcycle vehicle label\n",
    "motorcycle_accident[\"vehicle_type_label\"] = motorcycle_accident[\"vehicle_type\"].map(get_label(\"vehicle_type\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d18cab0-293d-4106-b406-44164e70cb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique vehicle types in the motorcycle accident data\n",
    "vehicle_types = motorcycle_accident['vehicle_type_label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fe305d-b144-4fab-bda2-207ca8573b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each vehicle type\n",
    "fig_count = 14\n",
    "for i, vehicle_type in enumerate(vehicle_types):\n",
    "    # Filter the data for the current vehicle type\n",
    "    data_subset = motorcycle_accident[motorcycle_accident['vehicle_type_label'] == vehicle_type]\n",
    "\n",
    "    # Create a countplot for the current vehicle type\n",
    "    plot = sns.countplot(data=data_subset, x='day_name', order=day_order, \n",
    "                     palette='rocket_r',\n",
    "                     edgecolor='black', \n",
    "                     alpha=0.8)\n",
    "    fig_count += 1\n",
    "    # initalize the display plot function\n",
    "    display_plot(plot, f\"FIGURE {fig_count}: {vehicle_type}\", 'DAYS', 'COUNT', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a4595f-93c8-4ab4-a885-7b2e253e176a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each vehicle type\n",
    "for j, vehicle_type in enumerate(vehicle_types):\n",
    "    # Filter the data for the current vehicle type\n",
    "    data_subset = motorcycle_accident[motorcycle_accident['vehicle_type_label'] == vehicle_type]\n",
    "    \n",
    "    # plot motorcycle accident time\n",
    "    plot_time = sns.histplot(data_subset, x='decimal_time', edgecolor='black', alpha=0.5, bins=20)\n",
    "    \n",
    "    fig_count += 1\n",
    "    # initalize the display plot function\n",
    "    display_plot(plot_time, f\"FIGURE {fig_count}: {vehicle_type}\",'TIME', 'COUNT', wide = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85914a8-8e0d-4d85-a75f-cf1bc4e34648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map accident vehicle type\n",
    "accident_vehicle['vehicle_type_label'] = accident_vehicle['vehicle_type'].map(get_label('vehicle_type'))\n",
    "\n",
    "top_10_casualty_classes = accident_vehicle['vehicle_type_label'].value_counts().nlargest(10).index\n",
    "\n",
    "# Filter the DataFrame to keep only the rows with the top 10 vehicle type\n",
    "accident_vehicle_top_10 = accident_vehicle[accident_vehicle['vehicle_type_label'].isin(top_10_casualty_classes)]\n",
    "\n",
    "# Create a stacked countplot using Seaborn with the filtered data\n",
    "casualty_type_by_sex_top_10 = sns.countplot(y='vehicle_type_label', hue='accident_severity_label', \n",
    "                                            data=accident_vehicle_top_10, palette='Paired', \n",
    "                                            orient='h', dodge=False, edgecolor='black', alpha=0.8)\n",
    "plt.legend(title='Severity')\n",
    "\n",
    "# initalize the display plot function\n",
    "display_plot(casualty_type_by_sex_top_10, 'FIGURE 14: TOP 10 ACCIDENT VEHICLES BY SEVERITY', \n",
    "             'COUNT', 'TYPE', wide = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c8ff31-b5c1-4c92-a5b3-633738e7aa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map driver age band label\n",
    "accident_vehicle['age_band_of_driver_label'] = accident_vehicle['age_band_of_driver'].map(\n",
    "    get_label('age_band_of_driver'))\n",
    "\n",
    "agebandidx = ['0 - 5', '6 - 10',\n",
    "              '11 - 15', '16 - 20', \n",
    "              '21 - 25', '26 - 35', \n",
    "              '36 - 45', '46 - 55',\n",
    "              '56 - 65', '66 - 75', \n",
    "              'Over 75']\n",
    "\n",
    "\n",
    "# plot vehivle driver band\n",
    "vehicle_driver_band_severity =  sns.countplot(x='age_band_of_driver_label', hue='accident_severity_label', \n",
    "                                 data=accident_vehicle, palette='Paired', orient='h',\n",
    "                                edgecolor='black', alpha=0.8, \n",
    "                                order=agebandidx, dodge=True)\n",
    "plt.legend(title='severity')\n",
    "\n",
    "# initalize the display plot function\n",
    "display_plot(vehicle_driver_band_severity, 'SEVERITY BY DRIVER AGE BAND', 'AGE BAND', 'COUNT', wide =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a535dd1f-896e-44ce-b9eb-47d0db6f587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the age band and vehicle type then calculate the counts\n",
    "grouped = accident_vehicle.groupby(['age_band_of_driver_label', 'vehicle_type_label']).size().unstack()\n",
    "\n",
    "# Reorder the index of 'grouped' DataFrame\n",
    "age_band_order = agebandidx\n",
    "grouped = grouped.reindex(age_band_order)\n",
    "\n",
    "# Set the Seaborn color palette\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "# Create a figure with a 2x3 grid of subplots\n",
    "fig, axs = plt.subplots(2, 3, figsize=(25, 18))\n",
    "\n",
    "# Flatten the axs array to easily access individual subplots\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Loop through each segment and plot the corresponding data\n",
    "for i in range(6):\n",
    "    start_col = i * len(grouped.columns) // 6\n",
    "    end_col = (i + 1) * len(grouped.columns) // 6\n",
    "    grouped.iloc[:, start_col:end_col].plot(kind='bar', stacked=True, ax=axs[i])\n",
    "    axs[i].set_xlabel('Age Band')\n",
    "    axs[i].set_ylabel('Count')\n",
    "    axs[i].set_title(f'Figure 13: Vehicles Types by Age Band (Part {i+1})')\n",
    "    axs[i].set_xticklabels(grouped.index, rotation=45)\n",
    "    axs[i].legend(title='Vehicle Type')\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('accident_vehicle_type_plot.png', dpi=700, bbox_inches='tight', format='png', \n",
    "                                       transparent = True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadd3fd8-bc16-4ac2-a057-a15779a1b1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map sex of driver label\n",
    "accident_vehicle['sex_label'] = accident_vehicle['sex_of_driver'].map(\n",
    "    get_label('sex_of_driver'))\n",
    "\n",
    "# plot vehicle driver\n",
    "vehicle_driver_band_gender =  sns.countplot(x='age_band_of_driver_label', hue='sex_label', \n",
    "                                 data=accident_vehicle, palette='Paired', orient='h',\n",
    "                                edgecolor='black', alpha=0.7, \n",
    "                                order=agebandidx, dodge=False)\n",
    "plt.legend(title='Gender')\n",
    "\n",
    "# initalize the display plot function\n",
    "display_plot(vehicle_driver_band_gender, 'DRIVER AGE BAND BY GENDER', 'AGE BAND', 'COUNT', wide = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfe8d2e-3455-4cb9-9589-358449bf9ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map  direction\n",
    "accident_vehicle['vehicle_direction_fr_label'] = accident_vehicle['vehicle_direction_from'].map(\n",
    "                                                get_label('vehicle_direction_from'))\n",
    "# plot severity by direction\n",
    "accident_vehicle_direction_from =  sns.countplot(y='vehicle_direction_fr_label', \n",
    "                                                hue='accident_severity_label', \n",
    "                                                orient='h',\n",
    "                                                data=accident_vehicle, palette='Paired',\n",
    "                                                edgecolor='black', alpha=0.8, dodge=False)\n",
    "\n",
    "    \n",
    "plt.legend(title='severity')\n",
    "\n",
    "# initalize the display plot function\n",
    "display_plot(accident_vehicle_direction_from, 'ACCIDENT SEVERITY BY DIRECTION FROM', \n",
    "             'COUNT', 'DIRECTION FROM', show_y_bar=True, wide= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857ecc74-c6c0-4479-a33b-24b6cdbf176f",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7fb999-f98a-4215-913a-14232c5feff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "humber_side_accidents = accident_data[accident_data['police_force']== 16].copy()\n",
    "humber_side_accidents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2762e4-39fd-46cb-8a58-5baede921c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "longitude_and_latitude = humber_side_accidents.loc[:, ['longitude', 'latitude']]\n",
    "longitude_and_latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3c70bd-fbfc-4ed6-9cd3-fd382a052e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the elbow method to determine the best k for geographic clustering\n",
    "max_k = 5\n",
    "K = range(1,max_k+5, 1)\n",
    "## iterations\n",
    "distortions = []\n",
    "\n",
    "for i in K:\n",
    "    model = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "    model.fit(longitude_and_latitude)\n",
    "    distortions.append(model.inertia_)\n",
    "\n",
    "elbow_plot = sns.lineplot(x=K, y=distortions, marker='x', linestyle='-', color='blue')\n",
    "display_plot(elbow_plot, 'FIGURE 23: ELBOW METHOD', 'NUMBER OF CLUSTERS', 'DISTORTION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e91d4f-0c6a-4184-8a50-ce6eb67f3a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines K-Means\n",
    "kmeans = KMeans(n_clusters = 5, random_state = 42)\n",
    "kmeans.fit(longitude_and_latitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ff3538-f2a4-4b1a-973c-4791ce4b45a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict labels\n",
    "labels = kmeans.predict(longitude_and_latitude)\n",
    "centroids = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d66f17c-1dd3-4af6-9d4b-517db8deef22",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bec544c-ee88-4104-8f64-5ab9658a4770",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423dc813-4f53-4c85-9707-51c21267ef74",
   "metadata": {},
   "outputs": [],
   "source": [
    "locationtuple = np.array(list(zip(longitude_and_latitude['longitude'], longitude_and_latitude['latitude'])))\n",
    "locationtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1301aa-4c33-4b5c-a328-0536da7f10e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_lat_severity = sns.scatterplot(data=humber_side_accidents, x=\"longitude\", y=\"latitude\", \n",
    "                                    hue=\"accident_severity_label\",\n",
    "                                    style=\"accident_severity_label\", \n",
    "                                    legend=\"full\", s=50, palette=\"Set1\", rasterized = True)\n",
    "sns.scatterplot(x=centroids[:,0], y=centroids[:,1], color = 'black', s=120)\n",
    "\n",
    "display_plot(long_lat_severity, 'FIGURE 24: LONGITUDE LATITUDE ACCIDENT SEVERITY HUE',\n",
    "             'LONGITUDE', 'LATITUDE', long=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba6b28d-b6ad-4d0a-b466-0e9797e3fcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "humber_side_accidents[\"urban_or_rural_area_labels\"] = humber_side_accidents[\"urban_or_rural_area\"].map(\n",
    "                                                                get_label(\"urban_or_rural_area\"))\n",
    "long_lat_urban = sns.scatterplot(data=humber_side_accidents, x=\"longitude\", y=\"latitude\", \n",
    "                                    hue=\"urban_or_rural_area_labels\",\n",
    "                                    s=50, palette=\"mako\", rasterized = True)\n",
    "sns.scatterplot(x=centroids[:,0], y=centroids[:,1], color = 'black', s=120)\n",
    "\n",
    "display_plot(long_lat_urban, 'FIGURE 25: LONGITUDE LATITUDE ACCIDENT URBAN & RURAL', \n",
    "             'LONGITUDE', 'LATITUDE', long=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b9f040-11a1-4489-a1ed-f0067eb2ee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "contamination = [0.0025, 0.001]\n",
    "model = LocalOutlierFactor(n_neighbors=30,contamination=contamination[0])\n",
    "y_pred = model.fit_predict(longitude_and_latitude)\n",
    "\n",
    "LOF_Scores = model.negative_outlier_factor_\n",
    "LOF_pred = pd.Series(y_pred).replace([-1,1], [1,0])\n",
    "LOF_pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c352b8d-e789-4eb8-a861-a6ecf4258780",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOF_anomalies = longitude_and_latitude[LOF_pred.values == 1]\n",
    "LOF_anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd873df4-47f7-40a7-965d-e1c7eb558956",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_lat_anomailes = sns.scatterplot(data=humber_side_accidents, x=\"longitude\", y=\"latitude\", \n",
    "                                      palette=\"husl\")\n",
    "sns.scatterplot(x=LOF_anomalies['longitude'], y=LOF_anomalies['latitude'], alpha = 0.9, marker='o', color='red')\n",
    "\n",
    "\n",
    "display_plot(long_lat_anomailes, 'HUMBER SIDE LONGITUDE LATITUDE ACCIDENT ANOMALIES', \n",
    "             'LONGITUDE', 'LATITUDE', long=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7899b0a-ebad-4afb-a715-6ac72254f231",
   "metadata": {},
   "source": [
    "## Viewining the cluster location on the humber side map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c16e79-8e52-498f-96e2-362a0a07ae30",
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude, longitude = 53.574501, -0.095008\n",
    "# Number of clusters you want to create\n",
    "num_clusters = 5\n",
    "\n",
    "# Select only the longitude and latitude columns for clustering\n",
    "X = humber_side_accidents[['longitude', 'latitude']]\n",
    "humber_side_accidents['cluster'] = labels\n",
    "\n",
    "# List comprehension to make out list of lists\n",
    "heat_data = [[row['latitude'],row['longitude']] for index, row in longitude_and_latitude.iterrows()]\n",
    "\n",
    "map_cluster = folium.Map(location=[latitude, longitude], zoom_start = 8.8)\n",
    "HeatMap(X.values).add_to(map_cluster)\n",
    "\n",
    "# Define cluster colors\n",
    "cluster_colors = ['yellow', 'green', 'brown', 'blue', 'orange']\n",
    "\n",
    "# Define hue colors (e.g., for different accident severity)\n",
    "hue_colors = {\n",
    "    'Fatal': '#4daf4a',\n",
    "    'Slight': '#377eb8',\n",
    "    'Serious': '#e41a1c'\n",
    "    # Add more severity and their corresponding colors here\n",
    "}\n",
    "\n",
    "# Add the points to the map with corresponding colors for each cluster and hue for each severity\n",
    "for cluster_id in range(num_clusters):\n",
    "    cluster_data = humber_side_accidents[humber_side_accidents['cluster'] == cluster_id]\n",
    "    for idx, row in cluster_data.iterrows():\n",
    "        # Get the severity for the current point\n",
    "        category = row['accident_severity_label']\n",
    "        \n",
    "        # Choose the color for the point based on cluster and hue (severity)\n",
    "        color = cluster_colors[cluster_id]\n",
    "        if category in hue_colors:\n",
    "            color = hue_colors[category]\n",
    "        \n",
    "            folium.CircleMarker(\n",
    "                location=[row['latitude'], row['longitude']],\n",
    "                radius=5,\n",
    "                color=cluster_colors[cluster_id],\n",
    "                fill=True,\n",
    "                fill_color=color,\n",
    "                fill_opacity=0.8\n",
    "            ).add_to(map_cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88593313-9618-42d3-b314-4c6274b3b4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_cluster.save('humberside_cluster_map.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c516c635-91ba-4dad-bfbd-8d4b5ca463ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47f4bdd-547d-4aa0-8a99-aab14c6dee13",
   "metadata": {},
   "source": [
    "## Analyzing Accident Severity with Apriori Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd398773-6363-4bf2-a215-7969bb3e3af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating data encoding for Apriori Algorithm.\n",
    "accident_details_encoding = pd.DataFrame()\n",
    "\n",
    "# list of selected columns\n",
    "selected_columns = ['accident_severity', 'road_type', \n",
    "                    'junction_detail', 'vehicle_type', \n",
    "                    'speed_limit', 'first_point_of_impact', \n",
    "                    'number_of_vehicles', 'number_of_casualties']\n",
    "\n",
    "# looping over columns to encode data\n",
    "encoded_data = []\n",
    "for column in selected_columns:\n",
    "    dummies = pd.get_dummies(accident_vehicle[column], prefix = column)\n",
    "    encoded_data.append(dummies)\n",
    "    \n",
    "accident_details_encoding = pd.concat(encoded_data, axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db471a70-5843-400d-b0cd-441111cbecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first 5 encoded data\n",
    "accident_details_encoding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614cc1e2-d28f-4b0e-9874-c03cf8d05728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define list of frequent set\n",
    "frequent_set = apriori(accident_details_encoding, min_support=0.4, use_colnames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7237e267-1aa8-4c7b-ac23-49174688bf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3ec6b7-5e6e-49c5-9048-8a347d3943cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining rules\n",
    "rules_by_lift = association_rules(frequent_set, metric='lift', min_threshold=1)\n",
    "rules_by_lift.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab40721-4a1e-491e-98f7-0de9b5cb1ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(rules_by_lift['support'], rules_by_lift['lift'], alpha=0.7, edgecolor='black')\n",
    "plt.title('FIGURE: Association Rule Strength (Lift vs Support)')\n",
    "plt.xlabel('Support')\n",
    "plt.ylabel('Lift')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce3346e-7376-40a2-acfb-55d538d01711",
   "metadata": {},
   "source": [
    "## Time Series \n",
    "create a separate time series model for each policing area chosen to predict weekly accident counts for 2019 based on historical data from 2017 to 2018. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0b0e8f-491f-407d-b7f6-a6a8ee245ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_data_v1 = DatabaseUtil('accident_data_v1.0.0_2023.db')\n",
    "accident_data_v1.connect_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd49bc11-991f-4195-b06c-28128163f56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents_all_years = accident_data_v1.tabulate_query(\"\"\"\n",
    "    SELECT *\n",
    "    FROM accident\n",
    "    WHERE accident_year IN (2017, 2018, 2019)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6def92-3eb5-40ca-9bf7-f8639101ce62",
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents_all_years.head()\n",
    "accidents_all_years['accident_year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ef8796-1a32-4a57-8e37-1025bbf6699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date column to datetime format\n",
    "accidents_all_years['date'] = pd.to_datetime(accidents_all_years['date'], format='%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ce84f2-ba5e-479f-b2f7-95abfc03d27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create weekly buckets\n",
    "accidents_all_years['week'] = accidents_all_years['date'].dt.to_period('W').apply(lambda r: r.start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2695c8d-1d66-448a-9f86-e3a2109f2adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_label(\"police_force\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf03207-9b9d-4ec5-9b1b-e4bde871609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouop by week and police force\n",
    "selected_police_forces = [1, 6, 17]\n",
    "\n",
    "weekly_grouped = (\n",
    "    accidents_all_years[accidents_all_years['police_force'].isin(selected_police_forces)]\n",
    "    .groupby(['police_force', 'week'])\n",
    "    .size()\n",
    "    .reset_index(name='weekly_accidents')\n",
    ")\n",
    "weekly_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d32acc-5205-4bd9-a0a8-3fae170cc1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pick one force\n",
    "pf = 1\n",
    "data_pf = weekly_grouped[weekly_grouped['police_force'] == pf].set_index('week')\n",
    "\n",
    "# Split into train (2017-2018) and test (2019)\n",
    "train = data_pf[data_pf.index.year < 2019]\n",
    "test = data_pf[data_pf.index.year == 2019]\n",
    "\n",
    "# Fit model\n",
    "model = ExponentialSmoothing(train['weekly_accidents'], trend='add', seasonal='add', seasonal_periods=52).fit()\n",
    "\n",
    "# Forecast for 2019\n",
    "forecast = model.forecast(len(test))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(train.index, train['weekly_accidents'], label='Train')\n",
    "plt.plot(test.index, test['weekly_accidents'], label='Actual 2019')\n",
    "plt.plot(test.index, forecast, label='Forecast 2019')\n",
    "plt.title(f\"Police Force {pf} Weekly Accident Forecast\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cf10ec-35bc-45cd-95ae-783bd76622f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pf in [1, 6, 17]:\n",
    "    data_pf = weekly_grouped[weekly_grouped['police_force'] == pf].set_index('week')\n",
    "    train = data_pf[data_pf.index.year < 2019]\n",
    "    test = data_pf[data_pf.index.year == 2019]\n",
    "    \n",
    "    model = ExponentialSmoothing(train['weekly_accidents'], trend='add', seasonal='add', seasonal_periods=52).fit()\n",
    "    forecast = model.forecast(len(test))\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(train.index, train['weekly_accidents'], label='Train')\n",
    "    plt.plot(test.index, test['weekly_accidents'], label='Actual 2019')\n",
    "    plt.plot(test.index, forecast, label='Forecast 2019')\n",
    "    plt.title(f\"Police Force {pf} Weekly Accident Forecast\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75044e56-98e2-4850-96db-531973ecd477",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "def forecast_weekly_by_force(weekly_grouped, forces=[1, 6, 17], seasonal_periods=52):\n",
    "    results = []\n",
    "\n",
    "    for pf in forces:\n",
    "        df_pf = weekly_grouped[weekly_grouped['police_force'] == pf].set_index('week').sort_index()\n",
    "\n",
    "        train = df_pf[df_pf.index.year < 2019]['weekly_accidents']\n",
    "        test  = df_pf[df_pf.index.year == 2019]['weekly_accidents']\n",
    "\n",
    "        if len(train) < seasonal_periods + 5 or len(test) == 0:\n",
    "            print(f\"Police Force {pf}: Not enough data to model. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Fit Holt-Winters model\n",
    "        model = ExponentialSmoothing(train, trend='add', seasonal='add', seasonal_periods=seasonal_periods)\n",
    "        model_fit = model.fit(optimized=True)\n",
    "        forecast = model_fit.forecast(len(test))\n",
    "\n",
    "        # Metrics\n",
    "        mae = mean_absolute_error(test, forecast)\n",
    "        rmse = np.sqrt(mean_squared_error(test, forecast))\n",
    "        results.append({'Police Force': pf, 'MAE': mae, 'RMSE': rmse})\n",
    "        print(f\"Police Force {pf} — MAE: {mae:.2f}, RMSE: {rmse:.2f}\")\n",
    "\n",
    "    return pd.DataFrame(results).sort_values(by='RMSE')\n",
    "\n",
    "\n",
    "        \n",
    "# Run the function\n",
    "metrics_df = forecast_weekly_by_force(weekly_grouped, forces=[1, 6, 17])\n",
    "display(metrics_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba6fdee-e164-43d3-a9d9-abf9dfe115f8",
   "metadata": {},
   "source": [
    "## LSOA forecasting for the city of hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63080cf3-f72c-48fc-a3e9-b994fade21e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_data['date'] = pd.to_datetime(accident_data['date'], format='%d/%m/%Y')\n",
    "\n",
    "# Filter just for Hull (local_authority_district 31 = Kingston upon Hull)\n",
    "hull_lsoas_only = accident_data[\n",
    "    (accident_data['accident_year'] == 2019) &\n",
    "    (accident_data['date'].between('2019-01-01', '2019-03-31')) &\n",
    "    (accident_data['local_authority_district'] == 31)\n",
    "]\n",
    "\n",
    "# Get top 30 LSOAs based on accident count\n",
    "top_30_lsoas = (\n",
    "    hull_lsoas_only['lsoa_of_accident_location']\n",
    "    .value_counts()\n",
    "    .nlargest(30)\n",
    "    .index\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6f093e-e65d-437b-9fe3-995dce6322c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Jan–June 2019 data for top 30 LSOAs\n",
    "hull_top30_jan_jul = accident_data[\n",
    "    (accident_data['accident_year'] == 2019) &\n",
    "    (accident_data['lsoa_of_accident_location'].isin(top_30_lsoas)) &\n",
    "    (accident_data['local_authority_district'] == 31)\n",
    "]\n",
    "\n",
    "# Aggregate daily accident counts\n",
    "daily_counts = (\n",
    "    hull_top30_jan_jul\n",
    "    .groupby('date')\n",
    "    .size()\n",
    "    .reindex(pd.date_range('2019-01-01', '2019-07-31'), fill_value=0)\n",
    "    .rename('daily_accidents')\n",
    "    .to_frame()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eecd00-d192-40f7-87d9-957147a0d25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# Split data\n",
    "train = daily_counts[:'2019-06-30']\n",
    "test = daily_counts['2019-07-01':]\n",
    "\n",
    "# Fit model (additive trend & seasonality — daily)\n",
    "model = ExponentialSmoothing(train['daily_accidents'], trend='add', seasonal=None)\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Forecast July\n",
    "forecast = model_fit.forecast(len(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbd2e0c-aeea-4b55-b7ea-982990c95486",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(train.index, train['daily_accidents'], label='Train (Jan–Jun)', color='blue')\n",
    "plt.plot(test.index, test['daily_accidents'], label='Actual (July)', color='black')\n",
    "plt.plot(test.index, forecast, label='Forecast (July)', linestyle='--', color='orange')\n",
    "plt.title('Daily Accident Forecast for Hull Top 30 LSOAs – July 2019')\n",
    "plt.xlabel('Date'); plt.ylabel('Accident Count')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9293d423-d5a4-4229-8358-f3a66c806008",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(test['daily_accidents'], forecast)\n",
    "rmse = np.sqrt(mean_squared_error(test['daily_accidents'], forecast))\n",
    "\n",
    "print(f\"MAE: {mae:.2f}, RMSE: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b866fa-89a2-4ace-a1aa-734b388d6481",
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_data_v1.disconnect_database() # Disconecting the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501c62d6-af43-43ec-83c4-147801e365c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Save images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b41ac3f-df6c-4ecd-b72e-df7f20db7fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_created_plots(created_plots):\n",
    "    folder_path = 'plot_visualisation' # Create plot destination.\n",
    "\n",
    "    try: \n",
    "        if not os.path.exists(folder_path): # Check if folder already exists\n",
    "            os.mkdir(folder_path)\n",
    "\n",
    "        for plot_name, plot_figure in created_plots.items():\n",
    "            plot_figure.figure.savefig('./' + folder_path + '/' + plot_name +'.png',\n",
    "                                       dpi=500, bbox_inches='tight', format='png', \n",
    "                                       transparent = True)\n",
    "\n",
    "        print(f\"Saved Created Plots, see the '{folder_path}' folder for images.\")\n",
    "    except OSError as error: \n",
    "        print(error) \n",
    "    \n",
    "\n",
    "save_created_plots(created_plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0851e2fb-ef9d-4c51-ba99-e0be01ebd774",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
